{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.数据预处理：\n",
    "\n",
    "首先用numpy.load将数据读入，通过对数据进行分析，发现训练数据一共是334条，特征向量为10000维的数据。其中119条数据为label=0的数据，即健康猪肉，另外215条数据为label=1的数据，即病死猪肉。\n",
    "\n",
    "然后进行数据预处理，采用numpy.vstack和numpy.hstack将数据预处理为tensorflow框架的输入格式。\n",
    "\n",
    "结果如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119, 10000) (215, 10000)\n",
      "(334, 10000)\n"
     ]
    }
   ],
   "source": [
    "# 训练数据\n",
    "data = np.load(\"train0.npy\")  # m=119, n=10000\n",
    "data1 = np.load(\"train1.npy\") # m=215, n=10000\n",
    "print(data.shape, data1.shape)\n",
    "X = np.vstack([data,data1]) # np.vstack() 在垂直方向上合并 119+215\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 2)\n"
     ]
    }
   ],
   "source": [
    "y1 = np.zeros((119,1))   # 对应train0  标签为0\n",
    "y1temp = np.ones((119,1))\n",
    "y1 = np.hstack((y1temp,y1)) # 水平方向上合并 119,1 + 119,1 = 119,2\n",
    "y2 = np.ones((215,1))    # 对应train1  标签为1\n",
    "y2temp = np.zeros((215,1))\n",
    "y2 = np.hstack((y2temp,y2))\n",
    "Y = np.vstack((y1,y2))\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预处理后标签Y \n",
    "\n",
    "其中，标签为[1,0]的向量标记为label=0，即健康的猪肉，标签为[0，1]的向量标记为label=1，即病死的猪肉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试数据\n",
    "testdata0 = np.load(\"test0a.npy\")  # m1= 20,n1= 10000\n",
    "testdata1 = np.load(\"test1a.npy\") # m1= 20,n1= 10000\n",
    "xt = np.vstack((testdata0,testdata1))\n",
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt1 = np.zeros((20,1))\n",
    "yt1temp = np.ones((20,1))\n",
    "yt1 = np.hstack((yt1temp,yt1))\n",
    "yt2 = np.ones((20,1))\n",
    "yt2temp = np.zeros((20,1))\n",
    "yt2 = np.hstack((yt2temp,yt2))\n",
    "yt = np.vstack((yt1,yt2))\n",
    "yt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用Tensorflow搭建神经网络框架：通过tf.Variable设置神经网络的连接权值weights和偏置biases。\n",
    "\n",
    "通过tf.reduce_sum函数来指定损失函数为预测值和真实值的交叉熵，\n",
    "\n",
    "然后通过梯度下降优化器tf.GradientDescent来最小化交叉熵。\n",
    "\n",
    "确定学习率为0.001，训练轮次为4000轮，每轮训练8条数据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置权重weights和偏置biases作为优化变量，初始值设为0\n",
    "weights = tf.Variable(tf.zeros([10000,2]))\n",
    "biases = tf.Variable(tf.zeros([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建神经网络模型\n",
    "x = tf.placeholder('float', [None, 10000])\n",
    "y = tf.placeholder('float', [None, 2])\n",
    "z = tf.matmul(x, weights) + biases\n",
    "pred = tf.nn.softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测值与真实值的交叉熵\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = pred))\n",
    "\n",
    "# 使用梯度下降优化器最小化交叉熵\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "# train =  tf.train.AdamOptimizer(0.005).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.5\n",
      "准确率： 0.775\n",
      "准确率： 0.775\n",
      "准确率： 0.8\n",
      "准确率： 0.8\n",
      "准确率： 0.8\n",
      "准确率： 0.8\n",
      "准确率： 0.775\n",
      "准确率： 0.775\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(4001):\n",
    "    sess.run(train, feed_dict={x:X, y:Y})\n",
    "    if i % 500 == 0:\n",
    "        predition = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        acc = tf.reduce_mean(tf.cast(predition, 'float'))\n",
    "        print('准确率：', sess.run(acc, feed_dict={x:xt, y:yt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改这段带代码，使用训练集进行验证\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={x:X, y_real:Y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.5\n",
      "准确率： 0.5\n",
      "准确率： 0.775\n",
      "准确率： 0.875\n",
      "准确率： 0.825\n",
      "准确率： 0.725\n",
      "准确率： 0.8\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.825\n",
      "准确率： 0.8\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.85\n",
      "准确率： 0.825\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.825\n",
      "准确率： 0.85\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.85\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.85\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.875\n",
      "准确率： 0.85\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.85\n",
      "准确率： 0.85\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.85\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n"
     ]
    }
   ],
   "source": [
    "# 设置权重weights和偏置biases作为优化变量，初始值设为0\n",
    "# 设置权重weights和偏置biases作为优化变量，初始值设为0\n",
    "weights = tf.Variable(tf.zeros([10000,2]))\n",
    "biases = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "# 构建神经网络模型\n",
    "x = tf.placeholder('float', [None, 10000])\n",
    "y = tf.placeholder('float', [None, 2])\n",
    "z = tf.matmul(x, weights) + biases\n",
    "pred = tf.nn.softmax(z)\n",
    "\n",
    "# 预测值与真实值的交叉熵\n",
    "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = pred))\n",
    "loss = -tf.reduce_mean(y * tf.log(pred))\n",
    "\n",
    "# 使用梯度下降优化器最小化交叉熵\n",
    "# train =  tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "# 开始训练\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "batch_size = 8\n",
    "for i in range(10001):\n",
    "    start = (i*batch_size) % 334\n",
    "    end = start + batch_size\n",
    "    sess.run(train, feed_dict={x:X[start:end], y:Y[start:end]})\n",
    "    if i % 200 == 0:\n",
    "        predition = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        acc = tf.reduce_mean(tf.cast(predition, 'float'))\n",
    "        print('准确率：', sess.run(acc, feed_dict={x:xt, y:yt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验结果：通过Tensorflow搭建的神经网络，设置每100轮输出结果，最终训练数据的准确率达到98.50%，测试数据的准确率达到85%。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验总结：\n",
    "\n",
    "通过上述实验，可以发现对于输入数据的特征向量为10000维的数据，神经网络仍可达到较好的拟合效果。对于测试数据为的准确率仅为85%，而训练数据的准确率高达98%，说明该网络对训练数据的学习过于深入，局部点陷入过拟合，导致鲁棒性较差。\n",
    "\n",
    "后期改进可以通过对损失函数加入惩罚项，即正则化的方式，还有采用随机梯度下降方式，并且对神经网络的连接参数进行一定的修改，可以一定程度上解决这个问题。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正则化是在神经网络计算损失值的过程中，在损失后面再加上一项。这样损失值所代表的输出与标准结果间的误差就会受到干扰，导致学习参数w 和 b无法按照目标方向来调整，实现模型无法与样本完全拟合，从而达到防止过拟合的效果。正则化主要有L1和L2正则，如下：\n",
    "\n",
    "    L1:所有学习参数w的绝对值的和\n",
    "\n",
    "    L2:所有学习参数w的平方和然后求平方根。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在TensorFlow中，已经封装好了相应的函数，\n",
    "\n",
    "    L2的正则化函数为：tf.nn.l2_loss(t, name=None)，\n",
    "    L1的正则化函数需要自己组合，tf.reduce_sum(tf.abs(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.5\n",
      "准确率： 0.5\n",
      "准确率： 0.75\n",
      "准确率： 0.875\n",
      "准确率： 0.8\n",
      "准确率： 0.725\n",
      "准确率： 0.8\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.825\n",
      "准确率： 0.75\n",
      "准确率： 0.825\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.85\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.85\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.85\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.875\n",
      "准确率： 0.875\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.875\n",
      "准确率： 0.85\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.875\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n",
      "准确率： 0.825\n"
     ]
    }
   ],
   "source": [
    "# 设置权重weights和偏置biases作为优化变量，初始值设为0\n",
    "# 设置权重weights和偏置biases作为优化变量，初始值设为0\n",
    "weights = tf.Variable(tf.zeros([10000,2]))\n",
    "biases = tf.Variable(tf.zeros([2]))\n",
    "\n",
    "# 构建神经网络模型\n",
    "x = tf.placeholder('float', [None, 10000])\n",
    "y = tf.placeholder('float', [None, 2])\n",
    "z = tf.matmul(x, weights) + biases\n",
    "pred = tf.nn.softmax(z)\n",
    "\n",
    "# 预测值与真实值的交叉熵\n",
    "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = pred))\n",
    "# loss = -tf.reduce_mean(y * tf.log(pred))\n",
    "L2 = tf.nn.l2_loss(weights)\n",
    "loss = -tf.reduce_mean(y * tf.log(pred)) + L2 * 0.01 # 正则化\n",
    "\n",
    "# 使用梯度下降优化器最小化交叉熵\n",
    "# train =  tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "# 开始训练\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "batch_size = 8\n",
    "for i in range(10001):\n",
    "    start = (i*batch_size) % 334\n",
    "    end = start + batch_size\n",
    "    sess.run(train, feed_dict={x:X[start:end], y:Y[start:end]})\n",
    "    if i % 200 == 0:\n",
    "        predition = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "        acc = tf.reduce_mean(tf.cast(predition, 'float'))\n",
    "        print('准确率：', sess.run(acc, feed_dict={x:xt, y:yt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用正则化的时候，我们为正则化项设置一个权重的系数，注意这个权重系数的值，可以通过不断尝试来确定权重系数的值。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
