{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从线性回归到逻辑回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在第2章，线性回归里面，我们介绍了一元线性回归，多元线性回归和多项式回归。这些模型都是广义线性回归模型的具体形式，广义线性回归是一种灵活的框架，比普通线性回归要求更少的假设。这一章，我们讨论广义线性回归模型的具体形式的另一种形式，逻辑回归（logistic regression）。\n",
    "\n",
    "<!-- TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和前面讨论的模型不同，逻辑回归是用来做分类任务的。\n",
    "\n",
    "分类任务的目标是找一个函数，把观测值匹配到相关的类和标签上。学习算法必须用成对的特征向量和对应的标签来估计匹配函数的参数，从而实现更好的分类效果。在二元分类（binary classification）中，分类算法必须把一个实例配置两个类别。\n",
    "\n",
    "二元分类案例包括，预测患者是否患有某种疾病，音频中是否含有人声，杜克大学男子篮球队在NCAA比赛中第一场的输赢。\n",
    "\n",
    "多元分类中，分类算法需要为每个实例都分类一组标签。本章，我们会用逻辑回归来介绍一些分类算法问题，研究分类任务的效果评价，也会用到上一章学的特征抽取方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归处理二元分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通的线性回归假设响应变量呈正态分布，也称为高斯分布（Gaussian distribution ）或钟形曲线（bell curve）。正态分布数据是对称的，且均值，中位数和众数（mode）是一样的。很多自然现象都服从正态分布。比如，人类的身高就服从正态分布，姚明那样的高度极少，在99%之外了。\n",
    "\n",
    "在某些问题里，响应变量不是正态分布的。比如，掷一个硬币获取正反两面的概率分布是伯努力分布（Bernoulli distribution），又称两点分布或者0-1分布。表示一个事件发生的概率是$P$，不发生的概率是$1-P$，概率在`{0,1}`之间。线性回归假设解释变量值的变化会引起响应变量值的变化，如果响应变量的值是概率的，这条假设就不满足了。广义线性回归去掉了这条假设，用一个联连函数(link function)来描述解释变量与响应变量的关系。实际上，在第2章，线性回归里面，我们已经用了联连函数。普通线性回归作为广义线性回归的特例使用的是恒等联连函数(identity link function)，将解释变量的通过线性组合的方式来联接服从正态分布的响应变量。如果响应变量不服从正态分布，就要用另外一种联连函数了。\n",
    "\n",
    "在逻辑回归里，响应变量描述了类似于掷一个硬币结果为正面的概率。如果响应变量等于或超过了指定的临界值，预测结果就是正面，否则预测结果就是反面。响应变量是一个像线性回归中的解释变量构成的函数表示，称为逻辑函数（logistic function）。一个值在`{0,1}`之间的逻辑函数如下所示：\n",
    "\n",
    "$$F(t)=\\frac 1 {1+e^{-t}}$$\n",
    "\n",
    "下面是$t$在`{-6,6}`的图形："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\msyh.ttc\", size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEACAYAAACuzv3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncjOzhnMhNzNrOBdyM7OG+/+cnNiSyEM6ngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19b03c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "plt.figure()\n",
    "plt.axis([-6, 6, 0, 1])\n",
    "plt.grid(True)\n",
    "X = np.arange(-6,6,0.1)\n",
    "y = 1 / (1 + np.e ** (-X))\n",
    "plt.plot(X, y, 'b-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在逻辑回归中，$t$是解释变量的线性组合，公式如下：\n",
    "\n",
    "$$F(t)=\\frac 1 {1+e^{-(\\beta_0+\\beta_x)}}$$\n",
    "\n",
    "对数函数（logit function）是逻辑函数的逆运算：\n",
    "\n",
    "$$g(x)=ln {\\frac {F(x)} {1-F(x)}} = \\beta_0+\\beta_x$$\n",
    "\n",
    "定义了逻辑回归的模型之后，我们用它来完成一个分类任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 垃圾邮件分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经典的二元分类问题就是垃圾邮件分类（spam classification）。这里，我们分类垃圾短信。我们用第三章介绍的TF-IDF算法来抽取短信的特征向量，然后用逻辑回归分类。\n",
    "\n",
    "我们可以用[UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)的短信垃圾分类数据集（SMS Spam Classification Data Set）。首先，我们还是用Pandas做一些描述性统计："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "含spam短信数量： 747\n",
      "含ham短信数量： 4825\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('mlslpic/SMSSpamCollection', delimiter='\\t', header=None)\n",
    "print(df.head())\n",
    "print('含spam短信数量：', df[df[0] == 'spam'][0].count()) # 垃圾邮件\n",
    "print('含ham短信数量：', df[df[0] == 'ham'][0].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每条信息的前面已经被打上了标签。共5574条短信里面，4827条是ham，747条是spam。ham短信用0标记，spam短信用1标记。观察数据会看到更多建模时需要的信息。下面的几条信息体现两种类型的特征：\n",
    "\n",
    "- Spam: Free entry in 2 a wkly comp to win FA Cup final tkts 21st May\n",
    "2005. Text FA to 87121 to receive entry question(std txt rate)T&C's\n",
    "apply 08452810075over18's\n",
    "- Spam: WINNER!! As a valued network customer you have been selected\n",
    "to receivea £900 prize reward! To claim call 09061701461. Claim code\n",
    "KL341. Valid 12 hours only.\n",
    "- Ham: Sorry my roommates took forever, it ok if I come by now?\n",
    "- Ham: Finished class where are you.\n",
    "\n",
    "让我们用`LogisticRegression`类来预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "首先，用pandas加载数据`.csv`文件，然后用`train_test_split`分成训练集（75%）和测试集（25%）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mlslpic/SMSSpamCollection', delimiter='\\t', header=None)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[1],\n",
    "df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "然后，我们建一个`TfidfVectorizer`实例来计算TF-IDF权重："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "最后，我们建一个`LogisticRegression`实例来训练模型。和`LinearRegression`类似，`LogisticRegression`同样实现了`fit()`和`predict()`方法。最后把结果打印出来看看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cc6ad3b9c04b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测类型：ham. 信息：Are u coming to the funeral home\n",
      "预测类型：ham. 信息：Love isn't a decision, it's a feeling. If we could decide who to love, then, life would be much simpler, but then less magical\n",
      "预测类型：ham. 信息：Dont think so. It turns off like randomlly within 5min of opening\n",
      "预测类型：spam. 信息：Hey happy birthday...\n",
      "预测类型：ham. 信息：None of that's happening til you get here though\n"
     ]
    }
   ],
   "source": [
    "for i, prediction in enumerate(predictions[-5:]):\n",
    "    print('预测类型：%s. 信息：%s' % (prediction, X_test_raw.iloc[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "分类模型的运行效果如何？有线性回归的度量方法在这里不太适用了。我们感兴趣的是分类是否正确（如第一章介绍的肿瘤预测问题），并不在乎它的决策范围。下面，我们来介绍二元分类的效果评估方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 二元分类效果评估方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "二元分类的效果评估方法有很多，常见的包括第一章里介绍的肿瘤预测使用的准确率（accuracy），精确率（precision）和召回率（recall）三项指标，以及综合评价指标（F1 measure）， ROC AUC值（Receiver Operating Characteristic ROC，Area Under Curve，AUC）。这些指标评价的样本分类是真阳性（true positives），真阴性（true negatives），假阳性（false positives），假阴性（false negatives）。阳性和阴性指分类，真和假指预测的正确与否。\n",
    "\n",
    "在我们的垃圾短信分类里，真阳性是指分类器将一个垃圾短信分辨为spam类。真阴性是指分类器将一个正常短信分辨为ham类。假阳性是指分类器将一个正常短信分辨为spam类。假阴性是指分类器将一个垃圾短信分辨为ham类。[混淆矩阵](https://www.cnblogs.com/cnkai/p/7755134.html)（Confusion matrix），也称列联表分析（Contingency table）可以用来描述真假与阴阳的关系。矩阵的行表示实际类型，列表示预测类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/ai_vivi/article/details/43836641"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [2 3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAADyCAYAAACrtLu6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngpnVOCGYWY0TgpnV/D+3bla9aWvKsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9cf1358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "y_test = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "y_pred = [0, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "plt.matshow(confusion_matrix)\n",
    "plt.title('混淆矩阵',fontproperties=font)\n",
    "plt.colorbar()\n",
    "plt.ylabel('实际类型',fontproperties=font)\n",
    "plt.xlabel('预测类型',fontproperties=font)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准确率是分类器预测正确性的评估指标。scikit-learn提供了`accuracy_score`来计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred, y_true = [0, 1, 1, 0], [1, 1, 1, 1]\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LogisticRegression.score()`用来计算模型预测的准确率："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.958373205742 [ 0.96291866  0.95334928  0.95813397  0.96172249  0.95574163]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "\n",
    "df = pd.read_csv('mlslpic/sms.csv')\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df['message'], df['label'])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "print('准确率：',np.mean(scores), scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你的结果可能和这些数字不完全相同，毕竟交叉检验的训练集和测试集都是随机抽取的。准确率是分类器预测正确性的比例，但是并不能分辨出假阳性错误和假阴性错误。在有些问题里面，比如第一章的肿瘤预测问题中，假阴性与假阳性要严重得多，其他的问题里可能相反。另外，有时准确率并非一个有效的衡量指标，如果分类的比例在样本中严重失调。比如，分类器预测信用卡交易是否为虚假交易时，假阴性比假阳性更敏感。为了提高客户满意度，信用卡部门更倾向于对合法的交易进行风险检查，往往会忽略虚假交易。因为绝大部分交易都是合法的，这里准确率不是一个有效的衡量指标。经常预测出虚假交易的分类器可能有很高的准确率，但是实际情况可能并非如此。因此，分类器的预测效果还需要另外两个指标：精确率和召回率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精确率和召回率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一章的肿瘤预测问题中精确率和召回率的定义我们已经介绍过。在本章的垃圾短信分类器中，精确率是指分类器预测出的垃圾短信中真的是垃圾短信的比例：\n",
    "\n",
    "$$P = \\frac {TP} {TP+FP}$$\n",
    "\n",
    "召回率在医学领域也叫做灵敏度（sensitivity），在本例中是指所有真的垃圾短信被分类器正确找出来的比例。\n",
    "\n",
    "$$R = \\frac {TP} {TP+FN}$$\n",
    "\n",
    "精确率和召回率各自含有的信息都很少，它们对分类器效果的观察角度不同。精确率和召回率都不能从表现差的一种分类器中区分出好的分类器。例如，假设一个测试集包括10个阳性和0个阴性结果。分类器即使将每一个样本都预测为阳性，其召回率都是1：\n",
    "\n",
    "$$R = \\frac {10} {10+0}=1$$\n",
    "\n",
    "分类器如果将每一个样本都预测为阴性，或者只是预测出假阳性和真阴性，其召回率都是0。类似的，一个分类器如果只预测一个样本，结果为阳性，而且这个样本确实为阳性，那么这个分类器就是100%精确的了。\n",
    "\n",
    "scikit-learn结合真实类型数据，提供了一个函数来计算一组预测值的精确率和召回率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精确率： 0.99217372134 [ 0.9875      0.98571429  1.          1.          0.98765432]\n",
      "召回率： 0.672121212121 [ 0.71171171  0.62162162  0.66363636  0.63636364  0.72727273]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "\n",
    "df = pd.read_csv('mlslpic/sms.csv')\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df['message'], df['label'])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "# 对数据集进行指定次数的交叉验证并为每次验证效果评测\n",
    "precisions = cross_val_score(classifier, X_train, y_train, cv=5, scoring='precision')\n",
    "print('精确率：', np.mean(precisions), precisions)\n",
    "recalls = cross_val_score(classifier, X_train, y_train, cv=5, scoring='recall')\n",
    "print('召回率：', np.mean(recalls), recalls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的分类器精确率99.2%，分类器预测出的垃圾短信中99.2%都是真的垃圾短信。召回率比较低67.2%，就是说真实的垃圾短信中，32.8%被当作正常短信了，没有被识别出来。这些数据会不断变化，因为训练集和测试集是随机抽取的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[模型中的交叉验证](https://blog.csdn.net/xiaodongxiexie/article/details/71915259)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算综合评价指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综合评价指标（F1 measure）是精确率和召回率的调和均值（harmonic mean），或加权平均值，也称为F-measure或fF-score。\n",
    "\n",
    "$$\\frac 1 {F1} + \\frac 1 {F1} = \\frac 1 P + \\frac 1 R $$\n",
    "\n",
    "即\n",
    "\n",
    "$$F1 = 2{\\frac {PR} {P+R}}$$\n",
    "\n",
    "综合评价指标平衡了精确率和召回率。一个二元分类模型，精确率和召回率为1，那么综合评价指标为1。如果精确率或召回率为0，那么综合评价指标为0。scikit-learn也提供了计算综合评价指标的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "综合评价指标： 0.800588878125 [ 0.82722513  0.76243094  0.79781421  0.77777778  0.83769634]\n"
     ]
    }
   ],
   "source": [
    "f1s = cross_val_score(classifier, X_train, y_train, cv=5, scoring='f1')\n",
    "print('综合评价指标：', np.mean(f1s), f1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本例的综合评价指标是80%。由于精确率和召回率的差异比较小，所以综合评价指标的罚值也比较小。有时也会用F0.5和F2，表示精确率权重大于召回率，或召回率权重大于精确率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC曲线（Receiver Operating Characteristic，ROC curve）可以用来可视化分类器的效果。和准确率不同，ROC曲线对分类比例不平衡的数据集不敏感，ROC曲线显示的是对超过限定阈值的所有预测结果的分类器效果。ROC曲线画的是分类器的召回率与误警率（fall-out）的曲线。误警率也称假阳性率，是所有阴性样本中分类器识别为阳性的样本所占比例：\n",
    "\n",
    "$$F = \\frac {FP} {TN+FP}$$\n",
    "\n",
    "AUC是ROC曲线下方的面积，它把ROC曲线变成一个值，表示分类器随机预测的效果。scikit-learn提供了计算ROC和AUC指标的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x6759470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "df = pd.read_csv('mlslpic/sms.csv')\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df['message'], df['label'])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict_proba(X_test)\n",
    "false_positive_rate, recall, thresholds = roc_curve(y_test, predictions[:, 1])\n",
    "roc_auc = auc(false_positive_rate, recall)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, recall, 'b', label='AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Fall-out')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网格搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在第二章我们曾经提到过超参数，是需要手动调节的参数，模型无法学习。比如，在我们的垃圾短信分类模型中，超参数出现在TF-IDF中，用来移除太频繁和太稀缺单词的频率阈值，目前函数正则化的权重值。在scikit-learn里面，超参数是在模型建立时设置的。在前面的例子中，我们没有为`LogisticRegression()`设置参数，是因为用的都是默认值。但是有时候默认值不一定是最优的。网格搜索（Grid search）就是用来确定最优超参数的方法。其原理就是选取可能的参数不断运行模型获取最佳效果。网格搜索用的是穷举法，其缺点在于即使每个超参数的取值范围都很小，计算量也是巨大的。不过这是一个并行问题，参数与参数彼此独立，计算过程不需要同步，所有很多方法都可以解决这个问题。scikit-learn有`GridSearchCV()`函数解决这个问题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed:   27.4s\n",
      "[Parallel(n_jobs=-1)]: Done 450 jobs       | elapsed:   54.2s\n",
      "[Parallel(n_jobs=-1)]: Done 800 jobs       | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1250 jobs       | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1800 jobs       | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2450 jobs       | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3200 jobs       | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4050 jobs       | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4608 out of 4608 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1536 candidates, totalling 4608 fits\n",
      "最佳效果：0.982\n",
      "最优参数组合：\n",
      "\tclf__C: 10\n",
      "\tclf__penalty: 'l2'\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__max_features: 2500\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__norm: 'l2'\n",
      "\tvect__stop_words: None\n",
      "\tvect__use_idf: True\n",
      "准确率： 0.989956958393\n",
      "精确率： 0.994252873563\n",
      "召回率： 0.930107526882\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "parameters = {\n",
    "    'vect__max_df': (0.25, 0.5, 0.75),\n",
    "    'vect__stop_words': ('english', None),\n",
    "    'vect__max_features': (2500, 5000, 10000, None),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__use_idf': (True, False),\n",
    "    'vect__norm': ('l1', 'l2'),\n",
    "    'clf__penalty': ('l1', 'l2'),\n",
    "    'clf__C': (0.01, 0.1, 1, 10),\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy', cv=3)\n",
    "\n",
    "df = pd.read_csv('mlslpic/sms.csv')\n",
    "X, y, = df['message'], df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('最佳效果：%0.3f' % grid_search.best_score_)\n",
    "print('最优参数组合：')\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "predictions = grid_search.predict(X_test)\n",
    "print('准确率：', accuracy_score(y_test, predictions))\n",
    "print('精确率：', precision_score(y_test, predictions))\n",
    "print('召回率：', recall_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`GridSearchCV()`函数的参数有待评估模型`pipeline`，超参数词典`parameters`和效果评价指标`scoring`。`n_jobs`是指并发进程最大数量，设置为`-1`表示使用所有CPU核心进程。在Python3.4中，可以写一个Python的脚本，让`fit()`函数可以在`main()`函数里调用，也可以在Python自带命令行,IPython命令行和IPython Notebook运行。经过网格计算后的超参数在训练集中取得了很好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 多类分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "现实中有很多问题不只是分成两类，许多问题都需要分成多个类，成为多类分类问题（Multi-class classification）。比如听到一首歌的样曲之后，可以将其归入某一种音乐风格。这类风格就有许多种。scikit-learn用one-vs.-all或one-vs.-the-rest方法实现多类分类，就是把多类中的每个类都作为二元分类处理。分类器预测样本不同类型，将具有最大置信水平的类型作为样本类型。`LogisticRegression()`通过one-vs.-all策略支持多类分类。下面，我们用它来分析一个多类分类问题。\n",
    "\n",
    "假设你想看电影，而你又非常讨厌看太次的电影。所以有品位的你可以在看每部电影之前都会看一堆影评，不过你更讨厌看影评。那么下面我们就用好影评来给电影分类。\n",
    "\n",
    "本例中，我们利用烂番茄（Rotten Tomatoes）网站影评短语数据对电影进行评价。每个影评可以归入下面5个类项：不给力（negative），不太给力（somewhat negative），中等（neutral），有点给力（somewhat positive）, 给力（positive）。解释变量不会总是直白的语言，因为影评内容千差万别，有讽刺的，否定的，以及其他语义的表述，语义并不直白，这些都会让分类充满挑战。数据集可以从[kaggle](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews)上下载。首先，我们还是用Pandas简单探索一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "# 压缩节省空间\n",
    "z = zipfile.ZipFile('mlslpic/train.zip')\n",
    "df = pd.read_csv(z.open(z.namelist()[0]), header=0, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId      156060\n",
       "SentenceId    156060\n",
       "Phrase        156060\n",
       "Sentiment     156060\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`Sentiment`是响应变量，`0`是不给力（negative），`4`是给力（positive），其他以此类推。`Phrase`列是影评的内容。影评中每句话都被分割成一行。我们不需要考虑`PhraseId`列和`SentenceId`列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A series of escapades demonstrating the adage ...\n",
       "1    A series of escapades demonstrating the adage ...\n",
       "2                                             A series\n",
       "3                                                    A\n",
       "4                                               series\n",
       "5    of escapades demonstrating the adage that what...\n",
       "6                                                   of\n",
       "7    escapades demonstrating the adage that what is...\n",
       "8                                            escapades\n",
       "9    demonstrating the adage that what is good for ...\n",
       "Name: Phrase, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Phrase.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    156060.000000\n",
       "mean          2.063578\n",
       "std           0.893832\n",
       "min           0.000000\n",
       "25%           2.000000\n",
       "50%           2.000000\n",
       "75%           3.000000\n",
       "max           4.000000\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.509945\n",
       "3    0.210989\n",
       "1    0.174760\n",
       "4    0.058990\n",
       "0    0.045316\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.value_counts()/df.Sentiment.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，近51%都是评价为`2`中等（neutral）的电影。可见，在这个问题里，准确率不是一个有信息量的评价指标，因为即使很烂的分类器预测出中等水平的结果，其准确率也是51%。`3`有点给力（somewhat positive）的电影占21%, `4`给力（positive）的电影占6%，共占27%。剩下的21%就是不给力（negative），不太给力（somewhat negative）的电影。用scikit-learn来训练分类器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done   1 jobs       | elapsed:    4.6s\n",
      "[Parallel(n_jobs=3)]: Done  50 jobs       | elapsed:  1.8min\n",
      "[Parallel(n_jobs=3)]: Done  68 out of  72 | elapsed:  3.0min remaining:   10.6s\n",
      "[Parallel(n_jobs=3)]: Done  72 out of  72 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "最佳效果：0.620\n",
      "最优参数组合：\n",
      "\tclf__C: 10\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__use_idf: False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import zipfile\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "parameters = {\n",
    "    'vect__max_df': (0.25, 0.5),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__use_idf': (True, False),\n",
    "    'clf__C': (0.1, 1, 10),\n",
    "}\n",
    "\n",
    "z = zipfile.ZipFile('mlslpic/train.zip')\n",
    "df = pd.read_csv(z.open(z.namelist()[0]), header=0, delimiter='\\t')\n",
    "X, y = df['Phrase'], df['Sentiment'].as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=3, verbose=1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('最佳效果：%0.3f' % grid_search.best_score_)\n",
    "print('最优参数组合：')\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print('\\t%s: %r' % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多类分类效果评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二元分类里，混淆矩阵可以用来可视化不同分类错误的数据。每种类型的精确率，召回率和综合评价指标（F1 score）可以计算，所有预测的准确率也可以计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.635024990388\n",
      "混淆矩阵： [[ 1178  1701   616    71     4]\n",
      " [  990  5993  6030   563    30]\n",
      " [  227  3231 32668  3520   143]\n",
      " [   37   401  6642  8089  1305]\n",
      " [    7    30   534  2397  1623]]\n",
      "分类报告：              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.33      0.39      3570\n",
      "          1       0.53      0.44      0.48     13606\n",
      "          2       0.70      0.82      0.76     39789\n",
      "          3       0.55      0.49      0.52     16474\n",
      "          4       0.52      0.35      0.42      4591\n",
      "\n",
      "avg / total       0.62      0.64      0.62     78030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = grid_search.predict(X_test)\n",
    "print('准确率：', accuracy_score(y_test, predictions))\n",
    "print('混淆矩阵：', confusion_matrix(y_test, predictions))\n",
    "print('分类报告：', classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们通过网格搜索获得了最佳参数组合，最终的分类器是通过对开始的分类器不断优化得到的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##多标签分类和问题转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面我们讨论了二元分类，多类分类，还有一种分类问题是多标签分类（multi-label classification）。每个样本可以拥有全部类型的一部分类型。这样的例子太普遍了，比如统计班上同学一周7天里哪天有空。每个同学都会在周一到周日这7天里，根据自己的情况分别打勾。再比如常见的博客文章分类标签，一篇文章一般都有好几个标签等等。多标签分类问题一般有两种解决方法。\n",
    "\n",
    "问题转化方法(Problem transformation)可以将多标签问题转化成单标签问题。 第一种转换方法是训练集里面每个样本通过幂运算转换成单标签。比如下面数据里面每篇文章都带有若干标签。\n",
    "\n",
    "![multi-label](mlslpic/4.1 multi-label.png)\n",
    "\n",
    "转换方法就是用幂运算将多个类合并成一个类，比如样本1有`Local`和`US`类，新建一个标签为`Local^US`类，这样多标签就变成单标签了。\n",
    "\n",
    "![multi-label-power-trans](mlslpic/4.2 multi-label-power-trans.png)\n",
    "\n",
    "这样原来5个标签现在变成了7个标签。这种幂运算虽然直观，但是并不实用，因为这样做多出来的标签只有一小部分样本会用到。而且，这些标签只能在训练集里面学习这些类似，在测试集中依然无法使用。\n",
    "\n",
    "另外一种问题转换方法就是每个标签都用二元分类处理。每个标签的分类器都预测样本是否属于该标签。我们的例子中需要5个二元分类器，第一个分类器预测样本是否应该被归入`Local`类，第二个分类器预测样本是否应该被归入`US`类，以此类推。预测最后一步就是把这些分类结果求并集，如下图所示。这个问题确保了单标签问题和多标签问题有同样的训练集，只是忽略了标签之间的关联关系。\n",
    "\n",
    "![multi-label-binary-trans](mlslpic/4.3 multi-label-binary-trans.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多标签分类效果评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多标签分类效果评估与多标签分类效果评估方式不同。最常用的手段是汉明损失函数（Hamming loss）和杰卡德相似度（Jaccard similarity）。汉明损失函数表示错误标签的平均比例，是一个函数，当预测全部正确，即没有错误标签时，值为0。杰卡德相似度或杰卡德相指数（Jaccard index），是预测标签和真实标签的交集数量除以预测标签和真实标签的并集数量。其值在`{0,1}`之间，公式如下：\n",
    "\n",
    "$$J(Predicted,True) = \\frac {|Predicted \\cap True|} {|Predicted \\cup True|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.25\n",
      "0.5\n",
      "1.0\n",
      "0.75\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import hamming_loss, jaccard_similarity_score\n",
    "print(hamming_loss(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[0.0, 1.0], [1.0, 1.0]])))\n",
    "print(hamming_loss(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [1.0, 1.0]])))\n",
    "print(hamming_loss(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [0.0, 1.0]])))\n",
    "print(jaccard_similarity_score(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[0.0, 1.0], [1.0, 1.0]])))\n",
    "print(jaccard_similarity_score(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [1.0, 1.0]])))\n",
    "print(jaccard_similarity_score(np.array([[0.0, 1.0], [1.0, 1.0]]), np.array([[1.0, 1.0], [0.0, 1.0]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章我们介绍了广义线性模型，是对普通线性回归中解释变量非正态分布情况的扩展。广义线性回归模型通过联接方程将解释变量和响应变量联接起来，和普通线性回归不同，这个方程可能是非线性的。我们重点介绍了逻辑联接方程，其图象是一种S曲线，对任意实数的返回值都在在`{0,1}`之间，如群体生长曲线。\n",
    "\n",
    "之后，我们介绍了逻辑回归，一种通过逻辑联接方程联接解释变量与呈伯努力分布的响应变量的关系。逻辑回归可用于解决二元分类问题，我们用它研究了典型的垃圾短信分类问题。紧接着我们介绍了多类分类问题，其类型空间超过两个，每个样本都有且仅有一种类型，我们用one-vs.-all策略研究了通过影评对电影分类的问题。最后，我们介绍了多标签分类，其类型空间超过两个，每个样本都有至少一种标签。介绍完广义线性模型的回归和分类问题，下一章我们就来介绍非线性模型的回归和分类问题——决策树。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
