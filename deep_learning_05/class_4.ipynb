{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras入门课4：自编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-66340f2868ba>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    " \n",
    "x_train, y_train = mnist.train.images, mnist.train.labels\n",
    "x_test, y_test = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784) (55000, 10)\n",
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化，将图像的像素归到0~1\n",
    "\n",
    "这样做的一个原因是 数字图像取值范围是0~255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数\n",
    "batch_size = 128\n",
    "n_epoch = 20\n",
    "\n",
    "# 图片维度\n",
    "img_rows, img_cols = 28, 28\n",
    "# denoising autoencoder参数\n",
    "n_visible = img_rows * img_cols\n",
    "n_hidden = 500\n",
    "corruption_level = 0.3  # ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 添加噪声\n",
    "\n",
    "X_train = x_train\n",
    "X_test  = x_test\n",
    "\n",
    "X_train_noisy = X_train + corruption_level * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape)\n",
    "X_test_noisy = X_test + corruption_level * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\n",
    "X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
    "X_test_noisy = np.clip(X_test_noisy, 0., 1.)\n",
    "print(X_train_noisy.shape)\n",
    "print(X_test_noisy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 784)               392784    \n",
      "=================================================================\n",
      "Total params: 785,284\n",
      "Trainable params: 785,284\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 构建autoencoder 模型\n",
    "input_img = Input(shape=(n_visible,))\n",
    "encoded=Dense(n_hidden,activation='relu')(input_img)\n",
    "decoded=Dense(n_visible,activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder=Model(inputs=input_img,outputs=decoded)\n",
    "autoencoder.compile(optimizer='adadelta',loss='binary_crossentropy')\n",
    "autoencoder.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 16s 298us/step - loss: 0.0719 - val_loss: 0.0055\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 15s 278us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 16s 300us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 15s 276us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 15s 264us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 15s 269us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 15s 273us/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 15s 279us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 19s 339us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 17s 314us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 17s 300us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 19s 344us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 19s 338us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 19s 348us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 18s 335us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 23s 418us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 23s 413us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 24s 436us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 26s 472us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 24s 430us/step - loss: 0.0040 - val_loss: 0.0041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f932848780>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "autoencoder.fit(X_train_noisy,X_train,epochs=n_epoch,batch_size=batch_size,\n",
    "                shuffle=True,verbose=1,validation_data=(X_test_noisy,X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 57us/step\n",
      "\n",
      "Summary: Loss over the test dataset: 0.00\n"
     ]
    }
   ],
   "source": [
    "# 评价模型\n",
    "evaluation=autoencoder.evaluate(X_test_noisy,X_test,batch_size=batch_size,verbose=1)\n",
    "print('\\nSummary: Loss over the test dataset: %.2f' % evaluation)\n",
    "# Summary: Loss over the test dataset: 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004081567785888911"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
