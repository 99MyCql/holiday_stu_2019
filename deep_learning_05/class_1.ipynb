{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一节课 使用Keras写一个mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlp就是multilayer perceptron，多层感知机。数据集用的是经典的mnist，数字分类问题。\n",
    "\n",
    "首先导入keras的各种模块\n",
    "\n",
    "keras.datasets 里面包含了多种常用数据集，如mnist，cifar10等等，可以实现自动下载和解析等等。\n",
    "\n",
    "keras.models 里面有最核心的模型结构，如顺序模型结构Sequential\n",
    "\n",
    "keras.layers 里面有一些常用的层结构，如全连接层Dense\n",
    "\n",
    "keras.optimizers 里面有一些常用优化函数，如adam等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入mnist数据，第一次会自动下载，之后运行会载入本地文件。\n",
    "\n",
    "注：这个方法非常慢，还是使用TF的数据集转换过来更为方便"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 09:26:31.788184  2860 deprecation.py:323] From <ipython-input-2-667e74665c93>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0725 09:26:31.789185  2860 deprecation.py:323] From D:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0725 09:26:31.790181  2860 deprecation.py:323] From D:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 09:26:32.099389  2860 deprecation.py:323] From D:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0725 09:26:32.106336  2860 deprecation.py:323] From D:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W0725 09:26:32.177179  2860 deprecation.py:323] From D:\\Program Files (x86)\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    " \n",
    "x_train, y_train = mnist.train.images, mnist.train.labels\n",
    "x_test, y_test = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↓查看一下数据格式，训练集一共有55000张，每一幅图像都转换为一个长向量，大小为28*28=784，代表大小是28*28,单通道灰度图，测试集是1000张。标签是列向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784) (55000, 10)\n",
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要进行卷积运算，则转为\n",
    "\n",
    "    x_train = x_train.reshape(-1, 28, 28,1).astype('float32')\n",
    "    x_test = x_test.reshape(-1,28, 28,1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↓可视化一些图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.84993768e-06,\n",
       "        5.78962909e-06, 4.64376490e-06, 7.11641906e-06, 3.67882672e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.42777661e-06,\n",
       "        8.32259138e-06, 1.41725295e-05, 1.41725295e-05, 1.41725295e-05,\n",
       "        1.41725295e-05, 1.41725295e-05, 1.41725295e-05, 1.51374670e-05,\n",
       "        1.51374670e-05, 1.49565412e-05, 1.53183919e-05, 1.47756155e-05,\n",
       "        1.41725295e-05, 1.14586392e-05, 1.26648126e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 8.44320857e-06, 1.51374670e-05,\n",
       "        1.53183919e-05, 1.53183919e-05, 1.53183919e-05, 1.53183919e-05,\n",
       "        1.53183919e-05, 1.53183919e-05, 1.53183919e-05, 1.53183919e-05,\n",
       "        1.53183919e-05, 1.53183919e-05, 1.53183919e-05, 1.53183919e-05,\n",
       "        1.53183919e-05, 1.53183919e-05, 1.13983306e-05, 1.38709845e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.36297513e-05, 1.53183919e-05,\n",
       "        1.25441957e-05, 1.20014183e-05, 1.20014183e-05, 1.20014183e-05,\n",
       "        1.20014183e-05, 8.38289998e-06, 3.67882672e-06, 3.67882672e-06,\n",
       "        3.67882672e-06, 3.67882672e-06, 3.67882672e-06, 7.71950545e-06,\n",
       "        1.33885169e-05, 1.53183919e-05, 1.53183919e-05, 1.13983306e-05,\n",
       "        1.26648126e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 2.29172815e-06, 4.94530786e-06,\n",
       "        7.84012229e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        2.05049355e-06, 1.28457395e-05, 1.53183919e-05, 1.53183919e-05,\n",
       "        6.93549282e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.06592505e-06, 1.53183919e-05, 1.53183919e-05,\n",
       "        1.41122209e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.06592505e-06, 1.53183919e-05, 1.53183919e-05,\n",
       "        1.41122209e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        6.39271548e-06, 9.46845557e-06, 1.53183919e-05, 1.53183919e-05,\n",
       "        1.46549983e-05, 3.07574032e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.50771587e-06,\n",
       "        7.05611046e-06, 1.37503685e-05, 1.37503685e-05, 1.37503685e-05,\n",
       "        1.52580842e-05, 1.53183919e-05, 1.53183919e-05, 1.53183919e-05,\n",
       "        1.53183919e-05, 1.44740725e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 4.10098710e-06, 7.17672765e-06, 1.32678997e-05,\n",
       "        1.53183919e-05, 1.53183919e-05, 1.53183919e-05, 1.53183919e-05,\n",
       "        1.53183919e-05, 1.53183919e-05, 1.53183919e-05, 1.53183919e-05,\n",
       "        1.53183919e-05, 8.56382576e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.23141933e-06,\n",
       "        1.12777134e-05, 1.52580842e-05, 1.53183919e-05, 1.53183919e-05,\n",
       "        1.53183919e-05, 1.34488255e-05, 1.24235785e-05, 1.24235785e-05,\n",
       "        4.52314771e-06, 4.10098710e-06, 1.29663567e-05, 1.53183919e-05,\n",
       "        1.53183919e-05, 7.05611046e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 6.81487563e-06, 1.32075911e-05,\n",
       "        1.53183919e-05, 1.45946897e-05, 1.36900599e-05, 6.93549282e-06,\n",
       "        5.36746802e-06, 1.86956765e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.20617269e-05, 1.53183919e-05,\n",
       "        1.45343811e-05, 2.47265393e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.01921587e-05, 1.53183919e-05,\n",
       "        1.06143189e-05, 3.73913531e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 2.89481454e-06, 1.39312942e-05, 1.53183919e-05,\n",
       "        1.41122209e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.08555537e-06, 7.47827062e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.06592505e-06, 1.53183919e-05, 1.53183919e-05,\n",
       "        1.00112329e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 8.38289998e-06, 1.53183919e-05, 1.43534553e-05,\n",
       "        3.43759211e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.26648129e-05, 1.50771584e-05, 1.53183919e-05, 1.01318501e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.45946897e-05, 1.53183919e-05, 1.44137639e-05, 3.43759211e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.36746802e-06,\n",
       "        1.51374670e-05, 1.45343811e-05, 5.18654224e-06, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.01543167e-07, 1.24235785e-05,\n",
       "        1.48359240e-05, 9.46845557e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.41234545e-07, 7.05611046e-06,\n",
       "        4.16129569e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "img1 = np.reshape(x_train[0],(28,28)) # 28x28 图片\n",
    "img2 = np.reshape(x_train[1],(28,28))\n",
    "print(img1.shape)\n",
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOHUlEQVR4nO3dS4xc5ZnG8ecBko2ThXEbsIixkwiZGUYaggwaCWMFRTGXje1FRjEXMRqgIxSkALMYcxFBMrbQaMiAN4aOQHFGgSjyRVgRKEFWZDMb5BsDhjaBQYztYPkCixCxyIDfWfRx1DF9vtOu26n2+/9Jrao6b52q1+V++pyqr875HBECcPY7p+0GAAwGYQeSIOxAEoQdSIKwA0mcN8gns81H/0CfRYSnWt7Vlt32Dbbfsf2e7dXdPBaA/nKn4+y2z5X0e0nflXRY0i5JqyLi7cI6bNmBPuvHlv1qSe9FxPsR8WdJv5S0vIvHA9BH3YT9YkmHJt0+XC37K7ZHbe+2vbuL5wLQpW4+oJtqV+ELu+kRMSZpTGI3HmhTN1v2w5LmT7r9NUkfdtcOgH7pJuy7JF1q++u2vyzp+5K29aYtAL3W8W58RHxm+x5Jv5F0rqTnIuKtnnUGoKc6Hnrr6Ml4zw70XV++VANg5iDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiY6nbMbZYcGCBcX6nXfeWaw/9NBDxXpplmB7yslG/2J8fLxYf/jhh4v1rVu3FuvZdBV22x9I+kTS55I+i4jFvWgKQO/1Yst+XUSc6MHjAOgj3rMDSXQb9pD0W9t7bI9OdQfbo7Z3297d5XMB6EK3u/HXRMSHti+Q9IrtAxGxc/IdImJM0pgk2a7/tAZAX3W1ZY+ID6vLY5K2Srq6F00B6L2Ow257lu2vnrouaZmk/b1qDEBvuTQOWlzR/oYmtubSxNuB5yNibcM67Mb3wdy5c2trDzzwQHHdW265pVifM2dOsd40Vt7NOHvT7+ahQ4eK9auuuqq2duLE2TuAFBFTvrAdv2ePiPcl/X3HHQEYKIbegCQIO5AEYQeSIOxAEoQdSKLjobeOnoyht440HUa6Zs2a2lrT/2+/h7+OHz9erJeMjIwU6wsXLizW33777dra5Zdf3klLM0Ld0BtbdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2GWDXrl3F+pVXXllb63acvTRWLUnXXXddsd7NoaRLliwp1nfs2FGsl/7t55139p5FnXF2IDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfYhcNlllxXrTePsH330UW2t6XjypnHw++67r1i/9957i/V169bV1g4ePFhct0nT7+7Jkydra3fffXdx3bGxsY56GgaMswPJEXYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzzwBN4/ClsfJupyYeHR0t1jds2FCsl6ZN3rt3b3HdlStXFuubNm0q1ku/2xdddFFx3Zk8pXPH4+y2n7N9zPb+ScvOt/2K7Xery9m9bBZA701nN/5nkm44bdlqSdsj4lJJ26vbAIZYY9gjYqekj09bvFzSxur6RkkretwXgB7r9ERcF0bEEUmKiCO2L6i7o+1RSeU3fgD6ru9n3YuIMUljEh/QAW3qdOjtqO15klRdHutdSwD6odOwb5N0e3X9dkkv9qYdAP3SuBtv+wVJ35Y0YvuwpB9LelzSr2zfIemgpO/1s8nsDhw40NpzNx0P/8477xTrpWPtm46VX726PMjTdM77fn7/YCZqDHtErKopfafHvQDoI74uCyRB2IEkCDuQBGEHkiDsQBJn77y1iSxdurS21nR4bNPQ2vj4eLG+aNGiYv21116rrc2dO7e4btPh102933jjjcV6NmzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtnPAjfffHNt7a677iqu23SYaNNYd9P6pbH0bg5RlaT169cX602nqs6GLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4+1mu2ym5+7n+q6++Wlz3/vvvL9YZRz8zbNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2c8Czz//fG1twYIFxXVHRkaK9abzzs+aNatYL3nkkUeKdcbRe6txy277OdvHbO+ftOxR23+w/Xr1c1N/2wTQrensxv9M0g1TLP+PiLii+nmpt20B6LXGsEfETkkfD6AXAH3UzQd099h+o9rNn113J9ujtnfb3t3FcwHoUqdh3yDpm5KukHRE0hN1d4yIsYhYHBGLO3wuAD3QUdgj4mhEfB4RJyX9VNLVvW0LQK91FHbb8ybdXClpf919AQwHT+O84C9I+rakEUlHJf24un2FpJD0gaQfRMSRxiezuzs4GgPXNM7+2GOPFesrVqyore3bt6+4btP86k3nlc8qIqY8IX/jl2oiYtUUi5/tuiMAA8XXZYEkCDuQBGEHkiDsQBKEHUiiceitp082g4feSlMPHz9+fICdzCwvv/xybe36668vrtt0Kuknn3yyo57OdnVDb2zZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJTiVdWbp0abH+xBO1J+PRgQMHiuvedtttHfV0Nli7dm1tbdmyZcV1Fy1a1Ot2UmPLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJpBlnLx2PLklPP/10sX7s2LHaWuZx9KYpm5955pnamj3lYdfoE7bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEmnH2lStXFutNx07v2LGjl+3MGE1TNm/evLlYL72uTXMWNJ0nAGemcctue77t39ket/2W7R9Vy8+3/Yrtd6vL2f1vF0CnprMb/5mkf4mIv5H0D5J+aPtvJa2WtD0iLpW0vboNYEg1hj0ijkTE3ur6J5LGJV0sabmkjdXdNkpa0a8mAXTvjN6z214o6VuSXpN0YUQckSb+INi+oGadUUmj3bUJoFvTDrvtr0jaLOneiPjjdA9iiIgxSWPVY8zYiR2BmW5aQ2+2v6SJoP8iIrZUi4/anlfV50mqPywMQOsat+ye2IQ/K2k8In4yqbRN0u2SHq8uX+xLhz2yc+fOYv2cc8p/90qnmr711luL646Pjxfre/bsKdabLFiwoLZ27bXXFtdtGpJcsaL8UUzTHl5peO2pp54qrttUx5mZzm78NZJuk/Sm7derZQ9qIuS/sn2HpIOSvtefFgH0QmPYI+K/JNX9+f5Ob9sB0C98XRZIgrADSRB2IAnCDiRB2IEk3HSYYU+fbIi/Qbdp06ZivTTe3M1YsyTt27evWG9yySWX1NbmzJlTXLfb3pvWL03ZvH79+uK6J06cKNYxtYiY8j+FLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4e6VpSueXXnqptrZ48eLiuidPnizW+znW3bTup59+Wqw3nc553bp1xfrWrVuLdfQe4+xAcoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7NM0MjJSW1uzZk1Xjz06Wp4da8uWLcV6N8d9N52bnWmTZx7G2YHkCDuQBGEHkiDsQBKEHUiCsANJEHYgicZxdtvzJf1c0kWSTkoai4inbD8q6S5Jx6u7PhgR9Qd9a2aPswMzRd04+3TCPk/SvIjYa/urkvZIWiHpHyX9KSL+fbpNEHag/+rCPp352Y9IOlJd/8T2uKSLe9segH47o/fsthdK+pak16pF99h+w/ZztmfXrDNqe7ft3V11CqAr0/5uvO2vSNohaW1EbLF9oaQTkkLSGk3s6v9zw2OwGw/0Wcfv2SXJ9pck/VrSbyLiJ1PUF0r6dUT8XcPjEHagzzo+EMYTpy59VtL45KBXH9ydslLS/m6bBNA/0/k0fomkVyW9qYmhN0l6UNIqSVdoYjf+A0k/qD7MKz0WW3agz7raje8Vwg70H8ezA8kRdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmg84WSPnZD0v5Nuj1TLhtGw9jasfUn01qle9ragrjDQ49m/8OT27ohY3FoDBcPa27D2JdFbpwbVG7vxQBKEHUii7bCPtfz8JcPa27D2JdFbpwbSW6vv2QEMTttbdgADQtiBJFoJu+0bbL9j+z3bq9vooY7tD2y/afv1tuenq+bQO2Z7/6Rl59t+xfa71eWUc+y11Nujtv9QvXav276ppd7m2/6d7XHbb9n+UbW81deu0NdAXreBv2e3fa6k30v6rqTDknZJWhURbw+0kRq2P5C0OCJa/wKG7aWS/iTp56em1rL9b5I+jojHqz+UsyPiX4ekt0d1htN496m3umnG/0ktvna9nP68E21s2a+W9F5EvB8Rf5b0S0nLW+hj6EXETkkfn7Z4uaSN1fWNmvhlGbia3oZCRByJiL3V9U8knZpmvNXXrtDXQLQR9oslHZp0+7CGa773kPRb23tsj7bdzBQuPDXNVnV5Qcv9nK5xGu9BOm2a8aF57TqZ/rxbbYR9qqlphmn875qIuFLSjZJ+WO2uYno2SPqmJuYAPCLpiTabqaYZ3yzp3oj4Y5u9TDZFXwN53doI+2FJ8yfd/pqkD1voY0oR8WF1eUzSVk287RgmR0/NoFtdHmu5n7+IiKMR8XlEnJT0U7X42lXTjG+W9IuI2FItbv21m6qvQb1ubYR9l6RLbX/d9pclfV/Sthb6+ALbs6oPTmR7lqRlGr6pqLdJur26frukF1vs5a8MyzTeddOMq+XXrvXpzyNi4D+SbtLEJ/L/I+mhNnqo6esbkv67+nmr7d4kvaCJ3br/08Qe0R2S5kjaLund6vL8IertPzUxtfcbmgjWvJZ6W6KJt4ZvSHq9+rmp7deu0NdAXje+LgskwTfogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJ/wftgrMNjgT54AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "im = plt.imshow(img1,cmap='gray')\n",
    "plt.show()\n",
    "im2 = plt.imshow(img2,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化，将图像的像素归到0~1\n",
    "\n",
    "这样做的一个原因是  数字图像取值范围是0~255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将label也转换成One-hot标签，如果标签不是onehot编码，则需要转换\n",
    "\n",
    "这里直接用keras的预置的一个函数 keras.utils.to_categorical"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 实际上读取到的数据，本身就是onehot编码，无需转换了\n",
    "y_train = keras.utils.to_categorical(y_train,10)\n",
    "y_test = keras.utils.to_categorical(y_test,10)\n",
    "\n",
    "print(y_train[0:10])#查看转换完毕的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0:10])# 查看原始标签 0~9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始构建模型，模型分包含两个隐层和一个输出层,都是全连接层，使用Sequential构建\n",
    "\n",
    "其中隐层输出采用ReLU激活函数，Sequential的第一层要指定input_shape，要注意，这里的input_shape 是不包含batch大小的，就只是后面几维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512,activation='relu',input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()#这一句用来输出网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_name': 'Dense',\n",
       "  'config': {'activation': 'relu',\n",
       "   'activity_regularizer': None,\n",
       "   'batch_input_shape': (None, 784),\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'dtype': 'float32',\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_1',\n",
       "   'trainable': True,\n",
       "   'units': 512,\n",
       "   'use_bias': True}},\n",
       " {'class_name': 'Dropout',\n",
       "  'config': {'name': 'dropout_1',\n",
       "   'noise_shape': None,\n",
       "   'rate': 0.2,\n",
       "   'seed': None,\n",
       "   'trainable': True}},\n",
       " {'class_name': 'Dense',\n",
       "  'config': {'activation': 'relu',\n",
       "   'activity_regularizer': None,\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_2',\n",
       "   'trainable': True,\n",
       "   'units': 512,\n",
       "   'use_bias': True}},\n",
       " {'class_name': 'Dropout',\n",
       "  'config': {'name': 'dropout_2',\n",
       "   'noise_shape': None,\n",
       "   'rate': 0.2,\n",
       "   'seed': None,\n",
       "   'trainable': True}},\n",
       " {'class_name': 'Dense',\n",
       "  'config': {'activation': 'softmax',\n",
       "   'activity_regularizer': None,\n",
       "   'bias_constraint': None,\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'bias_regularizer': None,\n",
       "   'kernel_constraint': None,\n",
       "   'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "    'config': {'distribution': 'uniform',\n",
       "     'mode': 'fan_avg',\n",
       "     'scale': 1.0,\n",
       "     'seed': None}},\n",
       "   'kernel_regularizer': None,\n",
       "   'name': 'dense_3',\n",
       "   'trainable': True,\n",
       "   'units': 10,\n",
       "   'use_bias': True}}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置模型，主要包括\n",
    "\n",
    "- loss：loss计算方法（损失函数）\n",
    "\n",
    "- optimizer：优化函数\n",
    "\n",
    "- metrics：指定哪些量需要在训练及测试中关注，一般都会写accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',  # 交叉熵\n",
    "             optimizer=RMSprop(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练。这里使用的是model对象的fit方法。\n",
    "\n",
    "前两个参数分别是**完整的训练数据和训练标签**\n",
    "\n",
    "batch_size 表示每一次塞入多少张图片\n",
    "\n",
    "epochs 表示训练几轮\n",
    "\n",
    "verbose 表示用何种方式显示输出信息，0表示不输出，1表示在一直输出更新，2表示每一个epoch才输出一次。\n",
    "\n",
    "validation_data 表示验证集，格式和训练集一样，如果此参数不为空的话，每一个epoch过后就会输出验证集的loss和accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 14s 256us/step - loss: 0.7288 - acc: 0.7763 - val_loss: 0.4500 - val_acc: 0.8551\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 14s 254us/step - loss: 0.3303 - acc: 0.9014 - val_loss: 0.2673 - val_acc: 0.9180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18c564d26a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=64,epochs=2,verbose=1,\n",
    "         validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试结果，输出为loss以及其他之前compile模型时指定过的metrics的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 85us/step\n",
      "Test loss: 0.2672776402115822\n",
      "Test accuracy 0.918\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test,verbose=1)\n",
    "print('Test loss:',score[0])\n",
    "print('Test accuracy',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2672776402115822, 0.918]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本文主要写了一个最简单的多层感知机模型，目的是熟悉keras最基本的操作。\n",
    "\n",
    "知识点：\n",
    "\n",
    "1. 学习载入Keras中预置的数据库及数据库数据的基本变换\n",
    "1. Sequential模型的定义，以及如何添加层\n",
    "1. 如何对Dense层及Dropout层进行基本的配置\n",
    "1. 学习使用compile对网络进行配置\n",
    "1. 使用fit方法来对小数据库进行训练，这里的小数据库指的是所有数据可以一次性载入到内存\n",
    "1. 使用evaluate方法来对模型进行效果评估\n",
    "\n",
    "参考：\n",
    "> https://github.com/keras-team/keras/tree/master/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
