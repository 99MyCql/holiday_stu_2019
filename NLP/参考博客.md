1、论文解读

	https://blog.csdn.net/hao5335156/article/details/84890802

	https://blog.csdn.net/hao5335156/article/details/84900239
	
	数据
		（中文分词、词频统计、词汇表）
	Embedding层的处理
		（矩阵向量化）
			46 X  128
			输入：词汇表长度
			输出：向量的表示长度
	CNN_Text 层
		（卷积神经网络分类）
				卷积核大小不一
			看图

2、Tensorflow-NLP实战

	NLP实践-Task1  THUCNews
	https://blog.csdn.net/yyy430/article/details/88072490
	
	最好先看看流程图
	

	2.1 数据集
	2.2 预处理
	2.3 搭建CNN模型
	2.4 训练与验证

	
3、文本特征处理
	两个比较好的博客系列
		NLP实战
		https://blog.csdn.net/yyy430/article/category/7619850
		
		NLP-learning
		https://blog.csdn.net/weixin_42483560/article/category/8347933
		
		jupyter-notebook
		
		
4、基于Text-CNN模型的中文文本分类实战

	https://blog.csdn.net/qq_22521211/article/details/88709769
	https://www.jianshu.com/p/e6d71a9b1554
	
	https://github.com/yongfengxuemei/NLP

	4.1 文本分类
	4.2 数据准备
		X为特征，文本分类中即为文本序列
		Y是标签，分类名称
	
		语料集（X,Y）的质量、数量决定了文本分类模型的分类效果
	4.3 文本预处理
		剔除无意义字符
		分词处理（推荐jieba）
		词干提取、词性还原、大小写转换
		去停用词
	4.4 文本的数值化【词向量技术】
		使用数字代表特定的词汇
		需要将词汇信息映射到一个数值化的语义空间中，这个语义空间我们可以称之为词向量空间（词向量模型）
		
		文本数值化方法：
			TF-IDF、BOW、One-Hot、
			分布式的表示方式（word2vec、Glove）
					看图【数据处理流程】
	4.5 文本分类模型
			文本分类技术路线
		
		Text-CNN 模型 
		
5、TextCNN文本分类（keras实现）

	没有提供数据集，但流程分析很详细
	https://blog.csdn.net/asialee_bird/article/details/88813385
	
	1、论文解读
		浅入层（输入层）
		卷积层
		池化层
		全连接层
		参数设置：
			sequence_length 定长处理
			num_classes  多分类
			vocabulary_size （语料库的词典大小, 记为|D|）
			embedding_size （将词向量的维度, 由原始的 |D| 降维到 embedding_size）
			filter_size_arr （多个不同size的filter）
	
	2、 Keras文本预处理
		2.1 读取数据集
		2.2 将文字转换成数字特征
				使用Keras的Tokenizer模块实现转换
				fit_on_texts()函数对每个词编号
				使用word_index属性可以看到每次词对应的编码
		2.3 将每条文本转换为数字列表
				将数据集中的每条文本转换为数字列表，使用每个词的编号进行编号
				使用该对象的texts_to_sequences（）函数，将每条文本转变成一个向量。 
		2.4 将每条文本设置为相同长度
				使用pad_sequences()让每句数字长度相同
		2.5 将每个词编码转换为词向量
			使用Embedding层将每个词编码转换为词向量
			通过神经网络的训练迭代更新得到一个合适的权重矩阵
			行大小为vocabulary_size，列大小为词向量的维度，将本来以one-hot编码的词向量映射到低维空间，得到低维词向量
		2.6 jupyter-notebook 
			keras-textcnn 预处理
		
5、			