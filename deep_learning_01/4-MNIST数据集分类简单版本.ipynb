{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络解决分类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784) (55000, 10)\n",
      "(10000, 784) (10000, 10)\n",
      "(5000, 784) (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "print(mnist.train.images.shape, mnist.train.labels.shape)\n",
    "print(mnist.test.images.shape, mnist.test.labels.shape)\n",
    "print(mnist.validation.images.shape, mnist.validation.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9185\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10])) # 10个分类，所以有十个输出\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x, W)+b)\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "# 交叉熵怎么定义？\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100) # 每次依次选一百个\n",
    "    train_step.run({x:batch_xs,y_:batch_ys})\n",
    "\n",
    "# 计算准确率\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(accuracy.eval({x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0720 16:23:56.732683 11056 deprecation.py:323] From <ipython-input-10-eab4fbd3e6db>:37: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.math.argmax` instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Texting acc 0.8323\n",
      "Iter 1, Texting acc 0.8708\n",
      "Iter 2, Texting acc 0.8804\n",
      "Iter 3, Texting acc 0.8882\n",
      "Iter 4, Texting acc 0.8937\n",
      "Iter 5, Texting acc 0.8973\n",
      "Iter 6, Texting acc 0.8992\n",
      "Iter 7, Texting acc 0.9021\n",
      "Iter 8, Texting acc 0.9037\n",
      "Iter 9, Texting acc 0.9052\n",
      "Iter 10, Texting acc 0.9066\n",
      "Iter 11, Texting acc 0.907\n",
      "Iter 12, Texting acc 0.9082\n",
      "Iter 13, Texting acc 0.9098\n",
      "Iter 14, Texting acc 0.9101\n",
      "Iter 15, Texting acc 0.911\n",
      "Iter 16, Texting acc 0.9117\n",
      "Iter 17, Texting acc 0.9125\n",
      "Iter 18, Texting acc 0.9124\n",
      "Iter 19, Texting acc 0.9133\n",
      "Iter 20, Texting acc 0.9136\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "\n",
    "\n",
    "# 定义每个批次的大小\n",
    "batch_size = 100\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# # 根据样本样式定义创建占位符（1列）\n",
    "x = tf.placeholder(tf.float32,[None,784]) # 每张图的像素点信息： 28*28 = 784\n",
    "y = tf.placeholder(tf.float32,[None,10])  # 十个数字\n",
    "\n",
    "# 定义神经网络的中间层\n",
    "# \n",
    "# 1行10列（输入层784个数据，中间层10个神经元）\n",
    "Weights_L1 = tf.Variable(tf.zeros([784,10])) \n",
    "biases_L1 =  tf.Variable(tf.zeros([10]))\n",
    "Wx_plus_b_L1 =  tf.matmul(x,Weights_L1) + biases_L1\n",
    "# 激活函数：softmax\n",
    "# 中间层输出：L1 （10个神经元）\n",
    "prediction = tf.nn.softmax(Wx_plus_b_L1)\n",
    "\n",
    "\n",
    "# 二次代阶函数\n",
    "loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "\n",
    "# 定义一个梯度下降法来进行训练的优化器\n",
    "train =  tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 结果存放在一个布尔型的列表中， 返回的是vector中的最大值的索引号\n",
    "correct_prediction = tf.equal(tf.arg_max(y,1),tf.arg_max(prediction,1))# argmax 返回一维张量中最大值的所以在位置\n",
    "# 求准确率\n",
    "# cast 把布尔型列表转换为float32， 如[true.true.false] =》 [1,1,0] ，那么准确率的值即为66.6%\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    # 初始化全部变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 训练21个周期\n",
    "    for epoch in range(21):\n",
    "        # n_batch ： 一共有多少个批次\n",
    "        for batch in range(n_batch):\n",
    "            # 保存batch_size张图片的数据与标签\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train,feed_dict={x:batch_xs,y:batch_ys})\n",
    "        \n",
    "        # 用测试集的图片及标签求得准确率\n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter \"+ str(epoch) + \", Texting acc \" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
